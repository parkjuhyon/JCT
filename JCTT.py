import streamlit as st
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain.embeddings.base import Embeddings
import cohere

# --- 1. API í‚¤ ë° ê¸°ë³¸ ì„¤ì • ---
# âš ï¸ ì£¼ì˜: ì´ ì½”ë“œë¥¼ ì™¸ë¶€ì— ê³µìœ í•  ê²½ìš° API í‚¤ê°€ ë…¸ì¶œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
cohere_client = cohere.Client(api_key="r1Fl17yD8nqp8yoYtnpiGKZXPMadYECdMJHZ1hCo")

# --- 2. Cohere Embeddings í´ë˜ìŠ¤ ì •ì˜ ---
class CohereEmbeddings(Embeddings):
    def __init__(self, client, model="embed-multilingual-v3.0"):
        self.client = client
        self.model = model

    def embed_documents(self, texts):
        input_texts = [t if isinstance(t, str) else t.page_content for t in texts]
        response = self.client.embed(
            texts=input_texts, model=self.model, input_type="search_document"
        )
        return response.embeddings

    def embed_query(self, text):
        response = self.client.embed(
            texts=[text], model=self.model, input_type="search_query"
        )
        return response.embeddings[0]

# --- 3. ë°ì´í„° ë¡œë”© ë° Retriever ì¤€ë¹„ (ë©”ì‹œì§€ ì—†ì´ ì¡°ìš©íˆ ì‹¤í–‰) ---
@st.cache_resource
def setup_retriever():
    # PDF íŒŒì¼ ë¡œë“œ
    pdf_files = ['H1J.pdf', 'H2J.pdf', 'H3J.pdf']
    documents = []
    for file in pdf_files:
        loader = PyPDFLoader(file)
        documents.extend(loader.load())

    # í…ìŠ¤íŠ¸ ë¶„í• 
    text_splitter = CharacterTextSplitter(chunk_size=700, chunk_overlap=200)
    texts = text_splitter.split_documents(documents)

    # ì„ë² ë”© ë° ë²¡í„° ìŠ¤í† ì–´ ìƒì„± (ë©”ëª¨ë¦¬ì—ì„œ)
    embeddings = CohereEmbeddings(client=cohere_client)
    vector_store = Chroma.from_documents(texts, embedding=embeddings) 
    
    # Retriever ë°˜í™˜
    return vector_store.as_retriever(search_kwargs={"k": 5})

def cohere_chat_generate(prompt: str) -> str:
    response = cohere_client.chat(message=prompt)
    return response.text

# --- 4. Streamlit UI êµ¬ì„± ---
st.set_page_config(page_title="PDF ê¸°ë°˜ í•™êµ ì „ìš© ì±—ë´‡", page_icon="ğŸ¤–", layout="wide")
st.title("í•™êµ ì „ìš© ì±—ë´‡ ( ì „ê³µì‹¬í™”íƒêµ¬ )")

# ì•± ì‹¤í–‰ ì‹œ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì¡°ìš©íˆ retrieverë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤.
retriever = setup_retriever()

# ì±„íŒ… ê¸°ë¡ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state["messages"] = [{
        "role": "assistant",
        "content": "ì•ˆë…•í•˜ì„¸ìš”! í•™êµì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”. (í•™ì‚¬ì¼ì •/êµìœ¡ê³¼ì • í¸ì„±í‘œ í•™ìŠµ ì™„ë£Œ, ì´ì— ê´€í•´ ì§ˆë¬¸ ê°€ëŠ¥)\nì˜ˆì‹œì§ˆë¬¸ : 1í•™ê¸° 2ì°¨ê³ ì‚¬ ì‹œí—˜ê¸°ê°„ ì•Œë ¤ì¤˜ / 2í•™ê¸° 3í•™ë…„ ì‹œí—˜ê¸°ê°„ ì•Œë ¤ì¤˜ / ì¸ê³µì§€ëŠ¥ ê¸°ì´ˆ ê³¼ëª©ì˜ ì„±ì  ì²˜ë¦¬ ìœ í˜•ì€ ë­ì•¼? / ì§„ë¡œê³¼ëª© ì•Œë ¤ì¤˜ / ê³µí†µê³¼ëª©ì˜ ê¸°ë³¸í•™ì , ìš´ì˜í•™ì  ì•Œë ¤ì¤˜"
    }]

# ì±„íŒ… ê¸°ë¡ í‘œì‹œ
for msg in st.session_state["messages"]:
    st.chat_message(msg["role"]).write(msg["content"])

# ë‹µë³€ ìƒì„± í•¨ìˆ˜
def generate_response(user_question: str) -> str:
    docs = retriever.get_relevant_documents(user_question)
    context = "\n\n".join([doc.page_content for doc in docs])

    prompt = f"""Use the following pieces of context to answer the user's question shortly.
Given the following summaries of a long document and a question, create a final answer with references ("SOURCES"), use "SOURCES" in capital letters regardless of the number of sources.
If you don't know the answer, just say "I don't know", don't try to make up an answer.
You MUST answer in Korean and in Markdown format.

----------------
{context}

ì§ˆë¬¸: {user_question}
ë‹µë³€:"""
    return cohere_chat_generate(prompt)

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if user_input := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”."):
    st.session_state["messages"].append({"role": "user", "content": user_input})
    st.chat_message("user").write(user_input)

    answer = generate_response(user_input)
    st.session_state["messages"].append({"role": "assistant", "content": answer})
    st.chat_message("assistant").write(answer)

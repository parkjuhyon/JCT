# main.py
import os
import streamlit as st
import cohere
# from dotenv import load_dotenv # ì´ ì¤„ì„ ì‚­ì œí•˜ê±°ë‚˜ ì£¼ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain.embeddings.base import Embeddings

# --- 1. ì´ˆê¸° ì„¤ì • ë° ìƒìˆ˜ ì •ì˜ ---
# API í‚¤ë¥¼ ì½”ë“œì— ì§ì ‘ ì…ë ¥í•©ë‹ˆë‹¤.
# "ì—¬ê¸°ì—_ì‹¤ì œ_Cohere_API_í‚¤ë¥¼_ì…ë ¥í•˜ì„¸ìš”" ë¶€ë¶„ì„ ì‹¤ì œ í‚¤ë¡œ êµì²´í•´ì£¼ì„¸ìš”.
COHERE_API_KEY = "ì—¬ê¸°ì—_ì‹¤ì œ_Cohere_API_í‚¤ë¥¼_ì…ë ¥í•˜ì„¸ìš”" 

PDF_FILES = ['H1J.pdf', 'H2J.pdf', 'H3J.pdf']
PERSIST_DIRECTORY = "chroma_db"
COLLECTION_NAME = "school_bot"

# --- 2. Cohere Embeddings í´ë˜ìŠ¤ ì •ì˜ ---
class CohereEmbeddings(Embeddings):
    """Cohere APIë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•œ LangChain Embedding ë˜í¼ í´ë˜ìŠ¤"""
    def __init__(self, client, model="embed-multilingual-v3.0"):
        self.client = client
        self.model = model

    def embed_documents(self, texts: list[str]) -> list[list[float]]:
        response = self.client.embed(
            texts=texts, model=self.model, input_type="search_document"
        )
        return response.embeddings

    def embed_query(self, text: str) -> list[float]:
        response = self.client.embed(
            texts=[text], model=self.model, input_type="search_query"
        )
        return response.embeddings[0]

# --- 3. í•µì‹¬ ë¡œì§ í•¨ìˆ˜í™” ---
@st.cache_resource
def load_vector_store():
    """PDFë¥¼ ë¡œë“œí•˜ê³  Vector Storeë¥¼ ìƒì„± ë˜ëŠ” ë¡œë“œí•˜ëŠ” í•¨ìˆ˜ (Streamlit ìºì‹± í™œìš©)"""
    if not COHERE_API_KEY or COHERE_API_KEY == "ì—¬ê¸°ì—_ì‹¤ì œ_Cohere_API_í‚¤ë¥¼_ì…ë ¥í•˜ì„¸ìš”":
        st.error("Cohere API í‚¤ê°€ ì½”ë“œì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. COHERE_API_KEY ë³€ìˆ˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        st.stop()
    
    cohere_client = cohere.Client(api_key=COHERE_API_KEY)
    embeddings = CohereEmbeddings(client=cohere_client)

    # Vector DBê°€ ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
    if os.path.exists(PERSIST_DIRECTORY) and os.listdir(PERSIST_DIRECTORY):
        st.info("ê¸°ì¡´ Vector DBë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.")
        return Chroma(
            persist_directory=PERSIST_DIRECTORY,
            embedding_function=embeddings,
            collection_name=COLLECTION_NAME
        )

    # Vector DBê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
    st.info("ìƒˆë¡œìš´ Vector DBë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...")
    documents = []
    for file in PDF_FILES:
        if os.path.exists(file):
            loader = PyPDFLoader(file)
            documents.extend(loader.load())
        else:
            st.warning(f"PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file}")

    if not documents:
        st.error("ì²˜ë¦¬í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. PDF íŒŒì¼ ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        st.stop()

    text_splitter = CharacterTextSplitter(chunk_size=700, chunk_overlap=200)
    texts = text_splitter.split_documents(documents)
    
    vector_store = Chroma.from_documents(
        texts,
        embedding=embeddings,
        persist_directory=PERSIST_DIRECTORY,
        collection_name=COLLECTION_NAME
    )
    st.success("Vector DB ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    return vector_store

def generate_response(retriever, user_question: str) -> str:
    """RAG íŒŒì´í”„ë¼ì¸ì„ í†µí•´ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜"""
    docs = retriever.get_relevant_documents(user_question)
    context = "\n\n".join([doc.page_content for doc in docs])

    prompt = f"""ë‹¤ìŒ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ê°„ê²°í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.
ì°¸ê³  ìë£Œê°€ ìˆì„ ê²½ìš°, ëŒ€ë¬¸ìë¡œ "SOURCES"ë¥¼ ëª…ì‹œí•˜ê³  ì¶œì²˜ë¥¼ ë°íˆì„¸ìš”.
ë‹µì„ ëª¨ë¥¼ ê²½ìš°, ê¾¸ë©°ë‚´ì§€ ë§ê³  "ì˜ ëª¨ë¥´ê² ìŠµë‹ˆë‹¤"ë¼ê³ ë§Œ ë‹µë³€í•˜ì„¸ìš”.
ë°˜ë“œì‹œ í•œêµ­ì–´ì™€ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤.

----------------
{context}

ì§ˆë¬¸: {user_question}
ë‹µë³€:"""
    
    cohere_client = cohere.Client(api_key=COHERE_API_KEY)
    response = cohere_client.chat(message=prompt)
    return response.text

# --- 4. Streamlit UI êµ¬ì„± ---
st.set_page_config(page_title="PDF ê¸°ë°˜ í•™êµ ì „ìš© ì±—ë´‡", page_icon="ğŸ¤–", layout="wide")
st.title("ğŸ¤– í•™êµ ì „ìš© ì±—ë´‡ (ì „ê³µì‹¬í™”íƒêµ¬)")

try:
    vector_store = load_vector_store()
    retriever = vector_store.as_retriever(search_kwargs={"k": 5})

    if "messages" not in st.session_state:
        st.session_state["messages"] = [{
            "role": "assistant",
            "content": "ì•ˆë…•í•˜ì„¸ìš”! í•™êµì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”. (í•™ì‚¬ì¼ì • ë“±)"
        }]

    for msg in st.session_state["messages"]:
        st.chat_message(msg["role"]).write(msg["content"])

    if user_input := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”."):
        st.session_state["messages"].append({"role": "user", "content": user_input})
        st.chat_message("user").write(user_input)

        answer = generate_response(retriever, user_input)
        st.session_state["messages"].append({"role": "assistant", "content": answer})
        st.chat_message("assistant").write(answer)

except Exception as e:
    st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

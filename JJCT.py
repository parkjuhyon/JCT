import os
import streamlit as st
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain.embeddings.base import Embeddings
import cohere

# 1. í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (ë³¸ì¸ í‚¤ë¡œ ë°”ê¾¸ê¸°)
os.environ["COHERE_API_KEY"] = "r1Fl17yD8nqp8yoYtnpiGKZXPMadYECdMJHZ1hCo"
os.environ["CHROMA_API_IMPL"] = "chromadb"
os.environ["TOKENIZERS_PARALLELISM"] = "false"

# 2. ì½”íˆì–´ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
cohere_client = cohere.Client(api_key=os.environ["COHERE_API_KEY"])

# 3. Cohere ì„ë² ë”© í´ë˜ìŠ¤ ì •ì˜
class CohereEmbeddings(Embeddings):
    def __init__(self, client, model="embed-multilingual-v3.0"):
        self.client = client
        self.model = model

    def embed_documents(self, texts):
        input_texts = [t if isinstance(t, str) else t.page_content for t in texts]
        response = self.client.embed(
            texts=input_texts,
            model=self.model,
            input_type="search_document"
        )
        return response.embeddings

    def embed_query(self, text):
        response = self.client.embed(
            texts=[text],
            model=self.model,
            input_type="search_query"
        )
        return response.embeddings[0]

# 4. PDF íŒŒì¼ ë¡œë”© ë° ë¬¸ì„œ ë¶„í• 
pdf_files = ['H1J.pdf', 'H3J.pdf']  # íŒŒì¼ëª… ë³€ê²½ ê°€ëŠ¥
documents = []
for pdf_file in pdf_files:
    loader = PyPDFLoader(pdf_file)
    documents.extend(loader.load())

text_splitter = CharacterTextSplitter(chunk_size=700, chunk_overlap=200)
texts = text_splitter.split_documents(documents)

# 5. ì„ë² ë”© ê°ì²´ ìƒì„±
embeddings = CohereEmbeddings(client=cohere_client)

# 6. ë²¡í„°ìŠ¤í† ì–´ ë””ë ‰í† ë¦¬ ì¤€ë¹„
persist_dir = "./chroma_db"
if not os.path.exists(persist_dir):
    os.makedirs(persist_dir)

# 7. Chroma ë²¡í„°ìŠ¤í† ì–´ ìƒì„± (embedding ë‹¨ìˆ˜í˜•)
vector_store = Chroma.from_documents(
    texts,
    embedding=embeddings,
    persist_directory=persist_dir,
    collection_name="school_docs"
)

retriever = vector_store.as_retriever(search_kwargs={"k": 4})

# 8. Cohere ì±—ë´‡ ìƒì„± í•¨ìˆ˜
def cohere_chat_generate(prompt: str) -> str:
    response = cohere_client.chat(message=prompt)
    return response.text

# 9. Streamlit ì•± UI êµ¬ì„±
st.set_page_config(page_title="PDF ì§ˆë¬¸ ë‹µë³€ ì±—ë´‡", page_icon="ğŸ¤–", layout="wide")
st.title("ğŸ¤– í•™êµ ì „ìš© ì±—ë´‡ (ì „ê³µì‹¬í™”íƒêµ¬)")

if "messages" not in st.session_state:
    st.session_state["messages"] = [{"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! í•™êµì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”. (í•™ì‚¬ì¼ì •)"}]

for msg in st.session_state["messages"]:
    st.chat_message(msg["role"]).write(msg["content"])

# 10. ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„± í•¨ìˆ˜
def generate_response(user_question: str) -> str:
    docs = retriever.get_relevant_documents(user_question)
    context = "\n\n".join([doc.page_content for doc in docs])

    prompt = f"""ì•„ë˜ ë¬¸ì„œ ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì§§ê³  ëª…í™•í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.
ë‹¤ìŒ ë¬¸ì„œ ìš”ì•½ê³¼ ì§ˆë¬¸ì´ ì£¼ì–´ì§€ë©´, ë°˜ë“œì‹œ 'SOURCES'ë¼ëŠ” ë‹¨ì–´ì™€ í•¨ê»˜ ì¶œì²˜ë¥¼ ëª…ì‹œí•˜ë©° ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”.
ëª¨ë¥´ë©´ "ëª¨ë¥´ê² ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µë³€í•˜ê³ , ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”.
ë‹µë³€ì€ í•œêµ­ì–´ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.

----------------
{context}

ì§ˆë¬¸: {user_question}
ë‹µë³€:"""

    answer = cohere_chat_generate(prompt)
    return answer

# 11. ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if user_input := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”."):
    st.session_state["messages"].append({"role": "user", "content": user_input})
    st.chat_message("user").write(user_input)

    answer = generate_response(user_input)
    st.session_state["messages"].append({"role": "assistant", "content": answer})
    st.chat_message("assistant").write(answer)
